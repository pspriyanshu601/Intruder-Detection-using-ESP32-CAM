# -*- coding: utf-8 -*-
"""FinalYearProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UH8cYlYHe_QImI0fE6cPQvI7sm2YHcvL

Install Dependencies
"""

!pip install facenet-pytorch faiss-cpu flask-ngrok tqdm

""" Import Libraries"""

from facenet_pytorch import InceptionResnetV1, MTCNN
from PIL import Image
import torch
import numpy as np
import faiss
import os
from tqdm import tqdm
from flask import Flask, request, jsonify
from flask_ngrok import run_with_ngrok
import io

"""Setup MTCNN (face detector) and FaceNet (embedding model)"""

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
mtcnn = MTCNN(image_size=160, margin=0, device=device)
model = InceptionResnetV1(pretrained='vggface2').eval().to(device)

"""Upload and unzip dataset (upload ZIP file manually)"""

from google.colab import files
import shutil

print("Please upload your dataset ZIP file (structured by person folders)...")
uploaded = files.upload()
zip_name = list(uploaded.keys())[0]
shutil.unpack_archive(zip_name, 'dataset')

"""Build embedding index and label list"""

embeddings = []
labels = []
paths = []

for root, dirs, files_in_dir in os.walk('dataset'):
    for file in files_in_dir:
        if file.lower().endswith(('jpg', 'jpeg', 'png')):
            img_path = os.path.join(root, file)
            try:
                img = Image.open(img_path).convert('RGB')
                face = mtcnn(img)
                if face is not None:
                    emb = model(face.unsqueeze(0).to(device)).squeeze(0).detach().cpu().numpy()
                    embeddings.append(emb)
                    labels.append(os.path.basename(root))
                    paths.append(img_path)
            except Exception as e:
                print(f"Error processing {img_path}: {e}")

embeddings = np.array(embeddings).astype('float32')
print(f"‚úÖ Indexed {len(embeddings)} face images.")

"""Build Faiss Index"""

index = faiss.IndexFlatL2(embeddings.shape[1])
index.add(embeddings)

"""Upload and Match Query Image"""

# Step 0: Install dependencies and set up ngrok
!pip install -q pyngrok

from flask import Flask, request, jsonify
from pyngrok import ngrok, conf
from PIL import Image
import io
import torch
import numpy as np

# üîë Set your ngrok authtoken (you only need to do this once per session)
conf.get_default().auth_token = "2wczMgF7rlSM0EkZuX7LvgITQNf_7itKcLPyvqTW6qPSHZGtz"

# ‚úÖ Make sure the following objects are already defined earlier:
# mtcnn, model, device, index, labels

# Step 1: Initialize Flask app
app = Flask(__name__)

# Step 2: Define the face identification endpoint
@app.route("/identify", methods=["POST"])
def identify():
    if 'image' not in request.files:
        return jsonify({"error": "No image uploaded"}), 400

    file = request.files['image']
    try:
        img = Image.open(io.BytesIO(file.read())).convert('RGB')
        face = mtcnn(img)

        if face is None:
            return jsonify({"found": False, "reason": "No face detected"}), 200

        # üß† Get face embedding
        with torch.no_grad():
            emb = model(face.unsqueeze(0).to(device)).squeeze(0).cpu().numpy()
        emb = np.expand_dims(emb.astype('float32'), axis=0)

        # üîç Search in FAISS index
        D, I = index.search(emb, k=1)
        threshold = 1.0

        if D[0][0] < threshold:
            return jsonify({
                "found": True,
                "label": labels[I[0][0]],
                "distance": float(D[0][0])
            })
        else:
            return jsonify({
                "found": False,
                "closest_distance": float(D[0][0])
            })

    except Exception as e:
        return jsonify({"error": str(e)}), 500

# Step 3: Start ngrok tunnel and run the app
public_url = ngrok.connect(5000)
print("üöÄ Public URL:", public_url)

app.run(port=5000)